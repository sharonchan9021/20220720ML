{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "malware-classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/AFAgarap/malware-classification.git/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0aTekQnlLK3",
        "outputId": "ebac7fa6-b1e0-479b-e25c-684e1b85652c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'malware-classification'...\n",
            "remote: Enumerating objects: 398, done.\u001b[K\n",
            "remote: Counting objects: 100% (73/73), done.\u001b[K\n",
            "remote: Compressing objects: 100% (43/43), done.\u001b[K\n",
            "remote: Total 398 (delta 34), reused 60 (delta 27), pack-reused 325\u001b[K\n",
            "Receiving objects: 100% (398/398), 116.53 MiB | 10.00 MiB/s, done.\n",
            "Resolving deltas: 100% (183/183), done.\n",
            "Checking out files: 100% (31/31), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd malware-classification"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibFP-zNXmnCl",
        "outputId": "85054e3e-054b-4125-e08f-38e23d070608"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/malware-classification\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQEaj2uBoLzP",
        "outputId": "16ef99ee-b601-4259-83f3-32b032e0efe9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classifier.py    LICENSE    requirements.txt    \u001b[0m\u001b[01;34mtrained-gru-svm\u001b[0m/\n",
            "CONTRIBUTING.md  main.py    results_summary.py  \u001b[01;34mtrained-mlp-svm\u001b[0m/\n",
            "\u001b[01;34mdataset\u001b[0m/         \u001b[01;34mmodels\u001b[0m/    \u001b[01;32msetup.sh\u001b[0m*           \u001b[01;34mutils\u001b[0m/\n",
            "\u001b[01;34mfigures\u001b[0m/         README.md  \u001b[01;34mtrained-cnn-svm\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/8wingflying/20220720/main/week4_machineLearning/MLSecurity/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27qBpRUkoNk3",
        "outputId": "1aaa3972-d6e2-4361-b24c-736fc74bf48a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-08-10 21:23:15--  https://raw.githubusercontent.com/8wingflying/20220720/main/week4_machineLearning/MLSecurity/requirements.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 77 [text/plain]\n",
            "Saving to: ‘requirements.txt’\n",
            "\n",
            "\rrequirements.txt      0%[                    ]       0  --.-KB/s               \rrequirements.txt    100%[===================>]      77  --.-KB/s    in 0s      \n",
            "\n",
            "2022-08-10 21:23:15 (3.56 MB/s) - ‘requirements.txt’ saved [77/77]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bash setup.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AX9c_qUEmtx1",
        "outputId": "29295aa2-a40e-4911-a922-10fe6c0acb20"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3 is installed\n",
            "pip is installed\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow_gpu==1.15.4\n",
            "  Using cached tensorflow_gpu-1.15.4-cp37-cp37m-manylinux2010_x86_64.whl (411.0 MB)\n",
            "Collecting numpy==1.16.0\n",
            "  Downloading numpy-1.16.0-cp37-cp37m-manylinux1_x86_64.whl (17.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 17.3 MB 5.3 MB/s \n",
            "\u001b[?25hCollecting scikit_learn==0.19.1\n",
            "  Using cached scikit-learn-0.19.1.tar.gz (9.5 MB)\n",
            "Collecting tensorflow==1.15.4\n",
            "  Using cached tensorflow-1.15.4-cp37-cp37m-manylinux2010_x86_64.whl (110.5 MB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==1.15.4->-r requirements.txt (line 1)) (3.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==1.15.4->-r requirements.txt (line 1)) (1.15.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==1.15.4->-r requirements.txt (line 1)) (0.8.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==1.15.4->-r requirements.txt (line 1)) (1.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==1.15.4->-r requirements.txt (line 1)) (1.1.2)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "  Using cached tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==1.15.4->-r requirements.txt (line 1)) (1.1.0)\n",
            "Collecting keras-applications>=1.0.8\n",
            "  Using cached Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==1.15.4->-r requirements.txt (line 1)) (0.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==1.15.4->-r requirements.txt (line 1)) (1.14.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==1.15.4->-r requirements.txt (line 1)) (0.37.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==1.15.4->-r requirements.txt (line 1)) (3.17.3)\n",
            "Collecting gast==0.2.2\n",
            "  Using cached gast-0.2.2.tar.gz (10 kB)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
            "\u001b[K     |████████████████████████████████| 503 kB 48.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==1.15.4->-r requirements.txt (line 1)) (1.47.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow_gpu==1.15.4->-r requirements.txt (line 1)) (3.1.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow_gpu==1.15.4->-r requirements.txt (line 1)) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow_gpu==1.15.4->-r requirements.txt (line 1)) (57.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow_gpu==1.15.4->-r requirements.txt (line 1)) (3.4.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow_gpu==1.15.4->-r requirements.txt (line 1)) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow_gpu==1.15.4->-r requirements.txt (line 1)) (3.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow_gpu==1.15.4->-r requirements.txt (line 1)) (4.1.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow_gpu==1.15.4->-r requirements.txt (line 1)) (1.5.2)\n",
            "Building wheels for collected packages: scikit-learn, gast\n",
            "  Building wheel for scikit-learn (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for scikit-learn\u001b[0m\n",
            "\u001b[?25h  Running setup.py clean for scikit-learn\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7554 sha256=34134280adc0cf38288c6cc804321d15d5e9837e607023f38d7298febd16759a\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
            "Successfully built gast\n",
            "Failed to build scikit-learn\n",
            "Installing collected packages: numpy, tensorflow-estimator, tensorboard, keras-applications, gast, tensorflow-gpu, tensorflow, scikit-learn\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.8.0\n",
            "    Uninstalling tensorboard-2.8.0:\n",
            "      Successfully uninstalled tensorboard-2.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.2+zzzcolab20220719082949\n",
            "    Uninstalling tensorflow-2.8.2+zzzcolab20220719082949:\n",
            "      Successfully uninstalled tensorflow-2.8.2+zzzcolab20220719082949\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.2\n",
            "    Uninstalling scikit-learn-1.0.2:\n",
            "      Successfully uninstalled scikit-learn-1.0.2\n",
            "    Running setup.py install for scikit-learn ... \u001b[?25l\u001b[?25herror\n",
            "  Rolling back uninstall of scikit-learn\n",
            "  Moving to /usr/local/lib/python3.7/dist-packages/scikit_learn-1.0.2.dist-info/\n",
            "   from /usr/local/lib/python3.7/dist-packages/~cikit_learn-1.0.2.dist-info\n",
            "  Moving to /usr/local/lib/python3.7/dist-packages/scikit_learn.libs/\n",
            "   from /usr/local/lib/python3.7/dist-packages/~cikit_learn.libs\n",
            "  Moving to /usr/local/lib/python3.7/dist-packages/sklearn/\n",
            "   from /usr/local/lib/python3.7/dist-packages/~klearn\n",
            "\u001b[31mERROR: Command errored out with exit status 1: /usr/bin/python3 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-exotw8gy/scikit-learn_2bda672569764421819480264964580c/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-exotw8gy/scikit-learn_2bda672569764421819480264964580c/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-4tcml6w3/install-record.txt --single-version-externally-managed --compile --install-headers /usr/local/include/python3.7/scikit-learn Check the logs for full command output.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 main.py --model 1 --dataset ./dataset/malimg.npz --num_epochs 100 --penalty_parameter 10 --checkpoint_path ./checkpoint/ --log_path ./logs/ --result_path ./results/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_i9qyu12n2I8",
        "outputId": "38595f73-922f-4b22-b930-6cfbe546efc9"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/__init__.py:149: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.16.0\n",
            "  UserWarning)\n",
            "\n",
            "<log> Building graph...WARNING:tensorflow:From /content/malware-classification/models/cnn_svm.py:52: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/malware-classification/models/cnn_svm.py:312: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/malware-classification/models/cnn_svm.py:342: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/malware-classification/models/cnn_svm.py:93: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /content/malware-classification/models/cnn_svm.py:109: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/malware-classification/models/cnn_svm.py:111: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/malware-classification/models/cnn_svm.py:124: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n",
            "</log>\n",
            "WARNING:tensorflow:From /content/malware-classification/models/cnn_svm.py:172: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/malware-classification/models/cnn_svm.py:175: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/malware-classification/models/cnn_svm.py:175: The name tf.local_variables_initializer is deprecated. Please use tf.compat.v1.local_variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/malware-classification/models/cnn_svm.py:178: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/malware-classification/models/cnn_svm.py:180: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/malware-classification/models/cnn_svm.py:187: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2022-08-10 21:26:49.691291: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2022-08-10 21:26:49.695296: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n",
            "2022-08-10 21:26:49.695573: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1726d80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2022-08-10 21:26:49.695610: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "step: 0, training accuracy : 0.015625, training loss : 2571.993896484375\n",
            "step: 100, training accuracy : 0.6484375, training loss : 3.2738394737243652\n",
            "step: 200, training accuracy : 0.69140625, training loss : 1.8302898406982422\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "step: 300, training accuracy : 0.75390625, training loss : 1.2506747245788574\n",
            "step: 400, training accuracy : 0.78515625, training loss : 1.0510036945343018\n",
            "step: 500, training accuracy : 0.83203125, training loss : 0.7498033046722412\n",
            "step: 600, training accuracy : 0.859375, training loss : 0.6377118229866028\n",
            "step: 700, training accuracy : 0.875, training loss : 0.5705059766769409\n",
            "step: 800, training accuracy : 0.8984375, training loss : 0.4274405539035797\n",
            "step: 900, training accuracy : 0.9140625, training loss : 0.3865252137184143\n",
            "step: 1000, training accuracy : 0.93359375, training loss : 0.33258911967277527\n",
            "step: 1100, training accuracy : 0.953125, training loss : 0.3041776716709137\n",
            "step: 1200, training accuracy : 0.98828125, training loss : 0.2535812556743622\n",
            "step: 1300, training accuracy : 0.984375, training loss : 0.17683619260787964\n",
            "step: 1400, training accuracy : 0.9765625, training loss : 0.16747882962226868\n",
            "step: 1500, training accuracy : 0.984375, training loss : 0.14245404303073883\n",
            "step: 1600, training accuracy : 0.99609375, training loss : 0.12812428176403046\n",
            "step: 1700, training accuracy : 0.95703125, training loss : 0.14310431480407715\n",
            "step: 1800, training accuracy : 0.99609375, training loss : 0.11668812483549118\n",
            "step: 1900, training accuracy : 0.9453125, training loss : 0.17588700354099274\n",
            "step: 2000, training accuracy : 0.953125, training loss : 0.1237788200378418\n",
            "step: 2100, training accuracy : 0.9921875, training loss : 0.31337979435920715\n",
            "step: 2200, training accuracy : 1.0, training loss : 0.060910530388355255\n",
            "step: 2300, training accuracy : 1.0, training loss : 0.2676107585430145\n",
            "step: 2400, training accuracy : 0.99609375, training loss : 0.08715223520994186\n",
            "EOF -- Training done at step 2499\n",
            "step: 0, testing accuracy : 0.79296875, testing loss : 1.1257987022399902\n",
            "step: 100, testing accuracy : 0.79296875, testing loss : 1.1257987022399902\n",
            "step: 200, testing accuracy : 0.79296875, testing loss : 1.1257987022399902\n",
            "step: 300, testing accuracy : 0.79296875, testing loss : 1.1257987022399902\n",
            "step: 400, testing accuracy : 0.79296875, testing loss : 1.1257987022399902\n",
            "step: 500, testing accuracy : 0.79296875, testing loss : 1.1257987022399902\n",
            "step: 600, testing accuracy : 0.79296875, testing loss : 1.1257987022399902\n",
            "step: 700, testing accuracy : 0.79296875, testing loss : 1.1257987022399902\n",
            "step: 800, testing accuracy : 0.79296875, testing loss : 1.1257987022399902\n",
            "step: 900, testing accuracy : 0.79296875, testing loss : 1.1257987022399902\n",
            "EOF -- Testing done at step 999\n"
          ]
        }
      ]
    }
  ]
}